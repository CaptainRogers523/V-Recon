# ğŸ” V-RECON v1.0

**Automated Reconnaissance Tool with Visual Intelligence** *By Vinayak Prajapati*

A comprehensive subdomain enumeration and URL discovery tool that combines multiple reconnaissance utilities into one automated workflow - now with **fast visual screenshot capabilities using Aquatone**.

---

## ğŸ“‹ Table of Contents

- [Features](#-features)
- [Tools Included](#-tools-included)
- [Installation](#-installation)
- [Usage](#-usage)
- [Output Structure](#-output-structure)
- [Legal Disclaimer](#-legal-disclaimer)
- [Troubleshooting](#-troubleshooting)

---

## âœ¨ Features

- **Automated subdomain discovery** using multiple sources
- **Live host detection** with HTTPX
- **ğŸ“¸ High-speed visual reconnaissance** with Aquatone screenshots
- **Deep web crawling** for URL and JavaScript discovery
- **Archive URL retrieval** from Wayback Machine
- **Parameter-based URL discovery**
- **Step-by-step execution** with real-time progress
- **Clean output structure** organized by target domain
- **Color-coded terminal output** for better readability
- **Smart confirmation** for large-scale scans (50+ hosts)

---

## ğŸ›  Tools Included

| Tool | Purpose |
|------|---------|
| **Subfinder** | Subdomain enumeration using passive sources |
| **Assetfinder** | Additional subdomain discovery |
| **HTTPX** | Fast HTTP probe for live host detection |
| **Aquatone** | ğŸ“¸ Visual reporting and Fly-over of web applications |
| **Katana** | Web crawling and JavaScript file discovery |
| **Waybackurls** | Fetch URLs from Wayback Machine |
| **GAU** | GetAllUrls - fetch known URLs from multiple sources |
| **Paramspider** | Discover URLs with parameters |
| **Hakrawler** | Additional web crawling |

---

## ğŸ“¦ Installation

### Prerequisites

- Linux/Unix system (Kali, Ubuntu, Debian, etc.)
- Internet connection
- Sudo privileges
- **Chromium/Chrome browser** (Required for Aquatone)

### Automated Installation

Run the installer script that will set up everything:

```bash
# Clone or download the repository
cd v-recon

# Make installer executable
chmod +x install_go_tools.sh

# Run the installer
./install_go_tools.sh
The installer will:

âœ… Install Go (if not present)

âœ… Configure PATH environment variables

âœ… Install all Go-based tools (including Aquatone)

âœ… Install Paramspider via apt/pip

âœ… Verify all installations

Post-Installation
After installation completes, restart your terminal or run:

Bash

source ~/.bashrc
# or
source ~/.zshrc
Verify Installation
Check if all tools are accessible:

Bash

subfinder -version
httpx -version
aquatone -version
katana -version
ğŸš€ Usage
Basic Usage
Bash

# Make the script executable
chmod +x v-recon.sh

# Run the script
./v-recon.sh
You'll be prompted to enter a target domain:

Enter domain: example.com
Example Scan
The script will automatically:

Find all subdomains

Check which hosts are live

ğŸ“¸ Take screenshots of live hosts using Aquatone

Crawl for URLs and JS files

Fetch archived URLs

Discover parameter-based URLs

Save everything to organized files

ğŸ“ Output Structure
All results are saved in a directory named after your target:

target-domain/
â”œâ”€â”€ subdomains.txt          # Subfinder results
â”œâ”€â”€ assetfinder.txt         # Assetfinder results
â”œâ”€â”€ all_subdomains.txt      # Combined unique subdomains
â”œâ”€â”€ live_hosts.txt          # Active/live hosts
â”œâ”€â”€ aquatone_out/           # ğŸ“¸ NEW: Visual recon folder
â”‚   â”œâ”€â”€ aquatone_report.html # Interactive HTML report with screenshots
â”‚   â”œâ”€â”€ screenshots/        # Full-size PNG files
â”‚   â””â”€â”€ html/               # Raw HTML source of pages
â”œâ”€â”€ katana_urls.txt         # URLs discovered by Katana
â”œâ”€â”€ js_files.txt            # JavaScript files found
â”œâ”€â”€ wayback_urls.txt        # Archived URLs from Wayback
â”œâ”€â”€ gau_urls.txt            # URLs from GAU
â”œâ”€â”€ param_urls.txt          # Parameter-based URLs
â””â”€â”€ hakrawler_urls.txt      # URLs from Hakrawler
Key Files
all_subdomains.txt - Complete unique subdomain list

aquatone_out/aquatone_report.html - ğŸ“¸ Visual overview of all live hosts

js_files.txt - JavaScript files for sensitive data discovery

param_urls.txt - URLs with parameters (useful for SQLi/XSS testing)

âš ï¸ Legal Disclaimer
IMPORTANT: This tool is designed for authorized testing only. The author is not responsible for misuse or any damage caused by this tool. Always stay within the scope of your target's policy.

ğŸ”§ Troubleshooting
Tools Not Found
If tools aren't accessible:

Bash

echo 'export PATH=$PATH:/usr/local/go/bin' >> ~/.bashrc
echo 'export PATH=$PATH:$HOME/go/bin' >> ~/.bashrc
source ~/.bashrc
Aquatone Issues
If Aquatone fails to take screenshots, ensure Chromium is installed:

Bash

sudo apt update && sudo apt install chromium-browser -y
Permission Denied
Bash

chmod +x v-recon.sh
chmod +x install_go_tools.sh
ğŸ“Š Performance Tips
For faster scans: Reduce crawl depth in Katana (default: -d 2)

Large Targets: If 50+ hosts are found, Aquatone will ask for confirmation.

Rate Limiting: If getting blocked, increase the timeout in the script.

ğŸ”„ Updates
Current Version: 5.6.3

To update tools to latest versions:

Bash

./install_go_tools.sh
ğŸ‘¤ Author
Vinayak Prajapati

ğŸ“ License
This tool is provided as-is for educational and authorized testing purposes only.

ğŸŒŸ Acknowledgments
Thanks to the creators of:

ProjectDiscovery (Subfinder, HTTPX, Katana)

Tom Hudson (Assetfinder, Waybackurls)

Devansh Batham (ParamSpider)

Luke Stephens (Hakrawler)

Michael Henriksen (Aquatone)

Happy Hunting! ğŸ¯
